{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Installs & import"
      ],
      "metadata": {
        "id": "44ejWnhAsgky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fancy_einsum einops tqdm torchtyping"
      ],
      "metadata": {
        "id": "bnVAViZf2pci",
        "outputId": "b3d931c5-4192-4b36-9d09-baf2ac0a8017",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fancy_einsum\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Collecting einops\n",
            "  Downloading einops-0.5.0-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n",
            "Collecting torchtyping\n",
            "  Downloading torchtyping-0.1.4-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from torchtyping) (1.12.1+cu113)\n",
            "Collecting typeguard>=2.11.1\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->torchtyping) (4.1.1)\n",
            "Installing collected packages: typeguard, torchtyping, fancy-einsum, einops\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 2.7.1\n",
            "    Uninstalling typeguard-2.7.1:\n",
            "      Successfully uninstalled typeguard-2.7.1\n",
            "Successfully installed einops-0.5.0 fancy-einsum-0.0.3 torchtyping-0.1.4 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KIxAKr_V2hb8"
      },
      "outputs": [],
      "source": [
        "\n",
        "import random\n",
        "import re\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import numpy as np\n",
        "import torch as t\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "from torchtyping import TensorType\n",
        "from tqdm.notebook import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modules & Transformer"
      ],
      "metadata": {
        "id": "yl_c5eM-so5Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "KmoZnRse2hb-"
      },
      "outputs": [],
      "source": [
        "# From previous exercises\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    pe: t.Tensor\n",
        "\n",
        "    def __init__(self, d_model: int, max_len: int = 5000, dropout: float = 0.1):\n",
        "        self.d_model = d_model\n",
        "        self.max_len = max_len\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.register_buffer(\n",
        "            \"pe\",    \n",
        "            self.encode(self.max_len, self.d_model)\n",
        "        )\n",
        "\n",
        "    def encode(self, seq_len: int, embedding_dim: int) -> t.Tensor:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        x: Tensor, shape [batch, seq_len, embedding_dim]\n",
        "        '''\n",
        "\n",
        "        _, seq_len, embedding_dim = x.shape\n",
        "\n",
        "        return x + self.pe[:seq_len, :embedding_dim].unsqueeze(0)\n",
        "\n",
        "\n",
        "class SinusoidalPositionalEncoding(PositionalEncoding):\n",
        "    def encode(self, seq_len: int, embedding_dim: int) -> t.Tensor:\n",
        "        i = t.arange(seq_len).unsqueeze(1)\n",
        "        d = t.arange(embedding_dim).unsqueeze(0)\n",
        "\n",
        "        return (\n",
        "            t.sin(i / 10000 ** (d / embedding_dim)) * (d % 2 == 0)\n",
        "            + t.cos(i / 10000 ** ((d - 1) / embedding_dim)) * (d % 2 == 1)\n",
        "        )\n",
        "\n",
        "def mask(A: TensorType[..., \"seq_len\", \"seq_len\"]) -> TensorType[..., \"seq_len\", \"seq_len\"]:\n",
        "    seq_len = A.shape[-1]\n",
        "\n",
        "    mask = t.triu(t.ones(seq_len, seq_len), diagonal=1).bool().to(device)\n",
        "    return A.masked_fill(mask, -np.inf)\n",
        "\n",
        "def multihead_masked_attention(\n",
        "    Q: TensorType[\"batch\", \"seq\", \"n_heads*headsize\"], \n",
        "    K: TensorType[\"batch\", \"seq\", \"n_heads*headsize\"], \n",
        "    V: TensorType[\"batch\", \"seq\", \"n_heads*headsize\"],\n",
        "    num_heads: int\n",
        ") -> TensorType[\"batch\", \"seq\", \"n_heads*headsize\"]:\n",
        "    '''\n",
        "    Should return the results of multihead self-attention.\n",
        "\n",
        "    Q: shape (batch, seq, n_heads*headsize)\n",
        "    K: shape (batch, seq, n_heads*headsize)\n",
        "    V: shape (batch, seq, n_heads*headsize)\n",
        "    num_heads: int\n",
        "\n",
        "    Return: shape (batch, seq, n_heads*headsize)\n",
        "    '''\n",
        "    _Q = einops.rearrange(Q, \"b s (n h) -> b n s h\", n=num_heads)    \n",
        "    _K = einops.rearrange(K, \"b s (n h) -> b n s h\", n=num_heads)    \n",
        "    _V = einops.rearrange(V, \"b s (n h) -> b n s h\", n=num_heads)\n",
        "\n",
        "    d_head = _Q.shape[-1]\n",
        "\n",
        "    A_pre: TensorType[\"b\", \"n\", \"s_q\", \"s_k\"] = mask(\n",
        "        einsum(\"b n s_q h, b n s_k h -> b n s_q s_k\", _Q, _K)\n",
        "    ) / np.sqrt(d_head)\n",
        "\n",
        "    A: TensorType[\"b\", \"n\", \"s_q\", \"s_k\"] = t.softmax(A_pre, dim=-1)\n",
        "    AV: TensorType[\"b\", \"n\", \"s_q\", \"h\"] = einsum(\"b n s_q s_k, b n s_k h -> b n s_q h\", A, _V)\n",
        "\n",
        "    return einops.rearrange(AV, \"b n s h -> b s (n h)\") \n",
        "\n",
        "\n",
        "class MultiheadMaskedAttention(nn.Module):\n",
        "    W_QKV: nn.Linear\n",
        "    W_O: nn.Linear\n",
        "\n",
        "    def __init__(self, hidden_size: int, num_heads: int):\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_heads = num_heads\n",
        "        self.head_size = hidden_size // num_heads\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.W_QKV = nn.Linear(hidden_size, hidden_size * 3)\n",
        "        self.W_O = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, x: TensorType[\"batch\", \"seq\", \"hidden_size\"]) -> TensorType[\"batch\", \"seq\", \"hidden_size\"]:\n",
        "        '''\n",
        "        x: shape (batch, seq, hidden_size)\n",
        "\n",
        "        Return: shape (batch, seq, hidden_size)\n",
        "        '''\n",
        "        Q, K, V = self.W_QKV(x).chunk(3, dim=-1)        \n",
        "        return self.W_O(multihead_masked_attention(Q, K, V, self.num_heads))\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class TransformerConfig:\n",
        "    '''Constants used throughout your decoder-only transformer model.'''\n",
        "\n",
        "    num_layers: int = 6\n",
        "    num_heads: int = 8\n",
        "    vocab_size: int = 256\n",
        "    hidden_size: int = 512\n",
        "    max_seq_len: int = 512\n",
        "    dropout: float = 0.1\n",
        "    layer_norm_epsilon: float = 1e-05\n",
        "\n",
        "config = TransformerConfig()\n",
        "\n",
        "class MLPBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size: int, dropout: float):\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(hidden_size, hidden_size * 4)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.linear2 = nn.Linear(hidden_size * 4, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        x = self.linear1(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size: int, num_heads: int, layer_norm_epsilon: float, dropout: float):\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_heads = num_heads\n",
        "        self.layer_norm_epsilon = layer_norm_epsilon\n",
        "        self.dropout = dropout\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.attention = MultiheadMaskedAttention(hidden_size, num_heads)\n",
        "        self.ln1 = nn.LayerNorm(hidden_size, eps=layer_norm_epsilon)\n",
        "        self.mlp = MLPBlock(hidden_size, dropout)\n",
        "        self.ln2 = nn.LayerNorm(hidden_size, eps=layer_norm_epsilon)\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        x = x + self.attention(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class DecoderOnlyTransformer(nn.Module):\n",
        "\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        self.config = config\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(config.vocab_size, config.hidden_size)\n",
        "        self.positional_embedding = SinusoidalPositionalEncoding(config.hidden_size, config.max_seq_len)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.decoder_blocks = nn.ModuleList([\n",
        "            DecoderBlock(config.hidden_size, config.num_heads, config.layer_norm_epsilon, config.dropout)\n",
        "            for _ in range(config.num_layers)\n",
        "        ])\n",
        "        self.ln = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_epsilon)\n",
        "        self.unembed = nn.Linear(config.hidden_size, config.vocab_size)        \n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        x = self.embedding(x)\n",
        "        x = self.positional_embedding(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for decoder_block in self.decoder_blocks:\n",
        "            x = decoder_block(x)\n",
        "        \n",
        "        x = self.ln(x)\n",
        "        x = self.unembed(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# %%\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ],
      "metadata": {
        "id": "p42TZHGTstCa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "mipscZr42hb_",
        "outputId": "2fdaa89f-45e4-497b-dedb-e05d01f9c3f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Prov', 'Fooles', 'duchies', 'willingly', 'quotidian', 'established', 'Advantage', '?\\n\\n                       ', 'Dolphin', 'Cotsole'] 34543\n",
            "# of tokens in corpus: 1987757\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from typing import Optional, Union\n",
        "\n",
        "\n",
        "with open(\"./shakespeare.txt\", \"r\") as f:\n",
        "    shakespeare = f.read()\n",
        "\n",
        "class WordsTokenizer():\n",
        "    def __init__(self, corpus: str):\n",
        "        self.from_tokens = list(set(re.split(r\"\\b\", corpus)))\n",
        "        self.to_tokens = {k: i for i, k in enumerate(self.from_tokens)}\n",
        "        self.vocab_size = len(self.from_tokens)\n",
        "\n",
        "    def encode(self, initial_text: str, return_tensors: Optional[str] = None) -> Union[list, np.ndarray, t.Tensor]:\n",
        "        tensors_list = [self.to_tokens[s] for s in re.split(r\"\\b\", initial_text) if len(s) > 0]\n",
        "        if return_tensors is None:\n",
        "            return tensors_list\n",
        "        elif return_tensors == \"pt\":\n",
        "            return t.tensor(tensors_list)\n",
        "        elif return_tensors == \"np\":\n",
        "            return np.array(tensors_list)\n",
        "        else:\n",
        "            raise Exception(\"Unexpected value for `return_tensors`.\")\n",
        "\n",
        "    def decode(self, list_of_ids: Union[t.Tensor, list]) -> str:\n",
        "        return ''.join([self.from_tokens[token] for token in list_of_ids])\n",
        "\n",
        "tokenizer = WordsTokenizer(shakespeare)\n",
        "shakespeare_encoded = tokenizer.encode(shakespeare, return_tensors=\"pt\").to(device)\n",
        "print(tokenizer.from_tokens[:10], len(tokenizer.from_tokens),)\n",
        "print(\"# of tokens in corpus:\", len(shakespeare_encoded))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "3WF4XItus7nP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "riVadohM2hcA",
        "outputId": "00c39c03-2a71-430c-ae50-1fbd4fa83ea1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# samples in train_data: 33129\n",
            "# samples in test_data: 8282\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class ShakespeareDataset(Dataset):\n",
        "    def __init__(self, tokens: Union[t.Tensor, list], seq_len: int):\n",
        "        self.inputs = []\n",
        "        self.targets = []\n",
        "\n",
        "        for i in range(0, len(tokens) - seq_len - 1, seq_len):\n",
        "            self.inputs.append(tokens[i : i + seq_len])\n",
        "            self.targets.append(tokens[i + 1 : i + seq_len + 1])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        input_ = self.inputs[idx]\n",
        "        target = self.targets[idx]\n",
        "        return input_, target\n",
        "\n",
        "train_corpus = shakespeare_encoded[:int(len(shakespeare_encoded) * 0.8)]\n",
        "test_corpus = shakespeare_encoded[int(len(shakespeare_encoded) * 0.8) :]\n",
        "\n",
        "seq_len = 48\n",
        "\n",
        "train_data = ShakespeareDataset(train_corpus, seq_len) # type: ignore\n",
        "test_data = ShakespeareDataset(test_corpus, seq_len) # type: ignore\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=True)\n",
        "\n",
        "print(\"# samples in train_data:\", len(train_data))\n",
        "print(\"# samples in test_data:\", len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer settings"
      ],
      "metadata": {
        "id": "WQTkZFx5s-4Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "HiRq6JMi2hcB",
        "outputId": "598e109b-5437-458f-b4cf-01f3230daa17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecoderOnlyTransformer(\n",
              "  (embedding): Embedding(34543, 512)\n",
              "  (positional_embedding): SinusoidalPositionalEncoding()\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (decoder_blocks): ModuleList(\n",
              "    (0): DecoderBlock(\n",
              "      (attention): MultiheadMaskedAttention(\n",
              "        (W_QKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLPBlock(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (gelu): GELU(approximate=none)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): DecoderBlock(\n",
              "      (attention): MultiheadMaskedAttention(\n",
              "        (W_QKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLPBlock(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (gelu): GELU(approximate=none)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (2): DecoderBlock(\n",
              "      (attention): MultiheadMaskedAttention(\n",
              "        (W_QKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLPBlock(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (gelu): GELU(approximate=none)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (3): DecoderBlock(\n",
              "      (attention): MultiheadMaskedAttention(\n",
              "        (W_QKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLPBlock(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (gelu): GELU(approximate=none)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (4): DecoderBlock(\n",
              "      (attention): MultiheadMaskedAttention(\n",
              "        (W_QKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLPBlock(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (gelu): GELU(approximate=none)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (5): DecoderBlock(\n",
              "      (attention): MultiheadMaskedAttention(\n",
              "        (W_QKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLPBlock(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (gelu): GELU(approximate=none)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (6): DecoderBlock(\n",
              "      (attention): MultiheadMaskedAttention(\n",
              "        (W_QKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLPBlock(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (gelu): GELU(approximate=none)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (7): DecoderBlock(\n",
              "      (attention): MultiheadMaskedAttention(\n",
              "        (W_QKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLPBlock(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (gelu): GELU(approximate=none)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (unembed): Linear(in_features=512, out_features=34543, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "config = TransformerConfig(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    hidden_size=512,\n",
        "    num_layers=8,\n",
        "    num_heads=8,\n",
        "    max_seq_len=48\n",
        ")\n",
        "\n",
        "transformer = DecoderOnlyTransformer(config)\n",
        "transformer.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "5q16xuuvtW0W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "LqFtfPQF2hcB"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(model, optimizer, loss_fn, trainloader, epochs, dataset_name=None, plot=True):\n",
        "\n",
        "    loss_list = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        progress_bar = tqdm(trainloader)\n",
        "        \n",
        "        for (x, y) in progress_bar:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            logits = model(x)\n",
        "            # logits dimensions are (batch, seq, digits), but we care about probabilities for each digit\n",
        "            # so we need to reshape into (batch * seq, digits)\n",
        "            loss = loss_fn(einops.rearrange(logits, \"b s d -> (b s) d\"), y.flatten())\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            \n",
        "            progress_bar.set_description(f\"epoch = {epoch+1}, loss = {loss.item():.4f}\")\n",
        "\n",
        "            loss_list.append(loss.item())\n",
        "    \n",
        "        if plot:\n",
        "            plt.plot(loss_list)\n",
        "            plt.title(f\"{dataset_name} loss\")\n",
        "            plt.show()\n",
        "    \n",
        "    return model    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "9yv0cs5Y2hcB",
        "outputId": "30153aa4-6aad-493d-bd7d-8cb63dfea74f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "af454aa3efac4bcc9c3f110f7c88e041",
            "4daafa4eb41c471698f3a01e9f515177",
            "64318378a3f546c29327940a34f04cd2",
            "355662bf44a0421a8a054b8bd3837d9f",
            "af0dfa63f670428ebf53a53311a03fbd",
            "61ab178441d443e8a8afd5fe46e7ebaf",
            "9106ef431b0d41e69641533d31467350",
            "a6f0c6d3b67c4539969e240e1bbfdbb8",
            "c562aee6241a4ca18d27fc7db143f64c",
            "558e0eb22457491685b52ad9163b975a",
            "a60238bfd84845159e951a9f9b63a704"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1036 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af454aa3efac4bcc9c3f110f7c88e041"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZd7G8e8vnSR0AtI7IkUEI0WQoqAIrn1Xsa664Lvr2htY1t59bbuu9bWsa1u7gisKiqIoGJDee4fQE0oI5Hn/mJJpCSEJJCfcn+viYubMmTnP4eg9zzztmHMOERHxnriKLoCIiJSOAlxExKMU4CIiHqUAFxHxKAW4iIhHKcBFRDxKAS5yAGa23MwGVnQ5RCIpwKVS8ofmRjNLC9n2JzObUIHFEqlUFOBSmcUD11d0IUQqKwW4VGZPALeYWa1YL5rZiWb2q5lt9/99YshrE8zsATP7ycxyzOxrM6sX8npPM5tkZtvMbIaZ9S9Jgcws2cyeMbO1/j/PmFmy/7V6Zjba/5lbzGyimcX5X7vdzNb4y7LAzE4pyz+MCCjApXLLAiYAt0S+YGZ1gDHAc0Bd4ClgjJnVDdntIuAKoD6QFPgcM2vsf++DQB3/9o/MLKMEZboT6AkcB3QBugN3+V+7GVgNZAANgDsAZ2ZHA38FTnDOVQdOA5aX4FgixVKAS2X3N+DaGOE6FFjknHvLObfPOfcuMB/4Xcg+rzvnFjrndgP/wRe6AJcAXzrnvnTOFTjnvsH3ZTGkBOW5GLjfObfROZcN3Adc6n8tH2gINHfO5TvnJjrfYkP7gWSgg5klOueWO+eWHOw/hEgkBbhUas652cBoYGTES42AFRHbVgCNQ56vD3m8C0j3P24O/N7f1LHNzLYBffCF74FEHneFfxv4mnwWA1+b2VIzG+k/h8XADcC9wEYze8/MGiFSRgpw8YJ7gOGEh/NafEEcqhmwpgSftwp4yzlXK+RPmnPu0RK8N/K4zfzbcM7lOOduds61As4Ebgq0dTvn3nHO9fG/1wGPleBYIsVSgEul56/Bvg9cF7L5S6CdmV1kZglmdgHQAV9t/UD+DfzOzE4zs3gzSzGz/mbWpATvfRe4y8wy/J2if/N/HmZ2hpm1MTMDtuNrOikws6PN7GR/Z+ceYDdQULKzFymaAly84n4gOCbcObcZOANfx+Fm4DbgDOfcpgN9kHNuFXAWvk7GbHw18lsp2f8PD+JrL58JzAKm+bcBtAXGAbnAz8A/nXPf4Wv/fhTYhK9Zpz4wqgTHEimW6YYOIiLepBq4iIhHKcBFRDxKAS4i4lEKcBERj0o4nAerV6+ea9GixeE8pIiI502dOnWTcy5qqYfDGuAtWrQgKyvrcB5SRMTzzCxy1jGgJhQREc9SgIuIeJQCXETEoxTgIiIepQAXEfEoBbiIiEcpwEVEPMoTAf7xtNW8PTnmMEgRkSOWJwL88xlref/XVRVdDBGRSsUTAW6Ali0XEQnnjQA3q+giiIhUOp4IcACHquAiIqE8EeBqQhERieaNADcFuIhIJE8EOJgaUEREIngiwH01cEW4iEgobwR4RRdARKQS8kaAK8FFRKJ4IsBBnZgiIpE8EeCGaRy4iEiEAwa4mb1mZhvNbHbItjpm9o2ZLfL/XftQFlLDCEVEopWkBv4GMDhi20hgvHOuLTDe//yQMUP1bxGRCAcMcOfcD8CWiM1nAW/6H78JnF3O5QpjmIYRiohEKG0beAPn3Dr/4/VAg6J2NLMRZpZlZlnZ2dmlO5pGoYiIRClzJ6bzVY2LrB475152zmU65zIzMjJKf5xSv1NEpGoqbYBvMLOGAP6/N5ZfkaIZKMFFRCKUNsA/By73P74c+Kx8ihObmdZCERGJVJJhhO8CPwNHm9lqM7sKeBQYZGaLgIH+54eMbzlZRbiISKiEA+3gnBtWxEunlHNZiqRhhCIi0TwyE1MTeUREInkjwLWalYhIFE8EOOiemCIikTwR4GpCERGJ5okAR4tZiYhE8USAm+bSi4hE8UaA656YIiJRvBHgFV0AEZFKyBMBDprIIyISyRMBrjvyiIhE80aA656YIiJRvBHgqoGLiETxToBXdCFERCoZTwS4xqGIiETzSICrCUVEJJInAtx0TzURkSjeCHBUAxcRieSNAFcnpohIlDIFuJldb2azzWyOmd1QXoWKOg6mtVBERCKUOsDNrBMwHOgOdAHOMLM25VWw8GOpBi4iEqksNfBjgMnOuV3OuX3A98C55VOscBpEKCISrSwBPhs4yczqmlkqMARoGrmTmY0wsywzy8rOzi71wdSCIiISrtQB7pybBzwGfA18BUwH9sfY72XnXKZzLjMjI6NUxzJTG7iISKQydWI65/7POXe8c64vsBVYWD7FinGsQ/XBIiIelVCWN5tZfefcRjNrhq/9u2f5FCvyOCjBRUQilCnAgY/MrC6QD1zjnNtWDmWK4ltOVkREQpUpwJ1zJ5VXQYpjGoYiIhLFEzMxQTc1FhGJ5IkAVxO4iEg0bwS47sgjIhLFIwGue2KKiETyRoCjGriISCRPBDhazEpEJIonAty0nJWISBRPBDigKriISARPBLhvPXAluIhIKG8EOOrEFBGJ5I0AVyemiEgUbwS47okpIhLFGwGuQSgiIlE8EeCgJhQRkUieCHB1YoqIRPNEgKsNRUQkmicCPBDf6sgUESnkjQD3J7jyW0SkUJkC3MxuNLM5ZjbbzN41s5TyKljYcfx1cOW3iEihUge4mTUGrgMynXOdgHjgwvIqWPixDsWnioh4W1mbUBKAamaWAKQCa8tepKKpDVxEpFCpA9w5twZ4ElgJrAO2O+e+jtzPzEaYWZaZZWVnZ5fqWMFOzNIWVkSkCipLE0pt4CygJdAISDOzSyL3c8697JzLdM5lZmRklPJYgc8qbWlFRKqesjShDASWOeeynXP5wMfAieVTrHBmgU5MJbiISEBZAnwl0NPMUs2XsKcA88qnWLGpBi4iUqgsbeCTgQ+BacAs/2e9XE7lCrM5dy8AH01bfSg+XkTEk8o0CsU5d49zrr1zrpNz7lLnXF55FSzUkuxcAP6TpQAXEQnwxEzMAn/bSZzGg4uIBHkiwANt38pvEZFCngjwwhq4IlxEJMATAR6ogSvARUQKeSLA9/sTXPktIlLIEwEeWAMlXr2YIiJBngjwgkAnpvJbRCTIIwGuTkwRkUieCPDgMEIFuIhIkEcCXBN5REQieSLACzSMUEQkiicCfH+BauAiIpE8EeAFwXHgSnARkQBPBHigEzNeAS4iEuSJAO/f3ncrtjrpSRVcEhGRysMTAX7bae0BqJemABcRCfBEgMfHGfFxFhyNIiIiHglw8I1AKdBNMUVEgkod4GZ2tJlND/mzw8xuKM/CRRxPNXARkRAJpX2jc24BcByAmcUDa4BPyqlcUeKscEamiIiUXxPKKcAS59yKcvq8KHFmakIREQlRXgF+IfBuOX1WTHFqQhERCVPmADezJOBM4IMiXh9hZllmlpWdnV2G46gTU0QkVHnUwE8HpjnnNsR60Tn3snMu0zmXmZGRUeqDxJmh/BYRKVQeAT6MQ9x8AhpGKCISqUwBbmZpwCDg4/IpTtHUiSkiEq7UwwgBnHM7gbrlVJZiaRy4iEg4T83E1DhwEZFCHgpwo6CgokshIlJ5eCjA1YkpIhLKMwGuNnARkXAeCnC1gYuIhPJMgGsYoYhIOA8FOGpCEREJ4aEAN5TfIiKFPBPgWsxKRCScZwLct5iVAlxEJMAzAZ6UEEdevmbyiIgEeCbAq6ckkLNnX0UXQ0Sk0vBQgCeyY09+RRdDRKTS8FCAqwYuIhLKMwFeIyWRHbtVAxcRCfBMgFdPSSB37z6NRBER8fNMgKcmJeAc7NFIFBERwFMBHg/Arr1qBxcRAU8G+P4KLomISOVQ1psa1zKzD81svpnNM7Ne5VWwSGnJvtt37lQNXEQEKONNjYFnga+cc+ebWRKQWg5liilQA9+Zpxq4iAiUIcDNrCbQF/gjgHNuL7C3fIoVLVADVxu4iIhPWZpQWgLZwOtm9puZvWpmaZE7mdkIM8sys6zs7OxSH0w1cBGRcGUJ8ASgG/CCc64rsBMYGbmTc+5l51ymcy4zIyOj1AdLS/LVwHfnqwYuIgJlC/DVwGrn3GT/8w/xBfohoRq4iEi4Uge4c249sMrMjvZvOgWYWy6liiFVbeAiImHKOgrlWuBt/wiUpcAVZS9SbNUSVQMXEQlVpgB3zk0HMsupLMWKjzOqJcarBi4i4ueZmZgAacnx7NRMTBERwGMBnpqUwG4FuIgI4LkAj2dnnppQRETAYwGelpygxaxERPw8FeCpSfFazEpExM9zAb5LwwhFRACPBXhaUoJq4CIifp4K8NTkeLWBi4j4eSrA05ISNJFHRMTPUwGempTAnvwC9hfozvQiIp4K8LRk3dhYRCTAUwGemhRYkVDt4CIingrwQA08Z49q4CIingrwOmlJAGzddchuvSki4hmeCvC6ackAbM7Nq+CSiIhUPG8FeLqvBr4pVzVwERFPBXjtVF+Ab9mpABcR8VSAJyXEUbNaoppQREQo4y3VzGw5kAPsB/Y55w757dXqpiWxSTVwEZEy39QYYIBzblM5fE6J1E1PYsXmnezJ30+K/0bHIiJHIk81oYBvJMrsNTv44+tTKrooIiIVqqwB7oCvzWyqmY2ItYOZjTCzLDPLys7OLuPhfGuCA/yydEuZP0tExMvKGuB9nHPdgNOBa8ysb+QOzrmXnXOZzrnMjIyMMh4OUpIKm02Wb9rJ3n0FnPX8T0xacthacUREKoUyBbhzbo3/743AJ0D38ihUcYaf1Cr4uP+TE5i6YiszVm3jolcm88WMtYf68CIilUapA9zM0syseuAxcCowu7wKVpSW9dIY0vmo4PPF2bnBx9e++xvv/7ryUBdBRKRSKEsNvAHwo5nNAKYAY5xzX5VPsYqXnlw4eGbeuh1hr93+0Sw2aZy4iBwBSh3gzrmlzrku/j8dnXMPlWfBijOsezO6NasFwDuTo2vcd34y63AVRUSkwnhuGCFA12a1+ejPJ9KwZkrM139avJnsnDzenryC3Vo7XESqKE8GOICZ8dywrjFfy83bxwkPjePOT2bz4Ji57NtfcJhLJyJy6Hk2wAGOqhG7Bh7q7ckruX/03MNQGhGRw8vTAV4jJbFE+42Zue4Ql0RE5PDzdICnpxSORln+6FCOaVgj5n710pMPV5FERA4bTwd4fJwBBMeFj762T8z9FmzIYceefB7+ch5PfbPwsJVPRORQKo/VCCvUvPsHkxjvC/JAoMeydttuXv5hKQA3DWp3WMomInIoeboGDlAtKZ6E+MLTaFYnNeZ+O3brTvYiUrV4PsAjffjnXtRK9XVuXt6reXD7B1mrgo+vffc3Lnz55+Dzn5dspsXIMSzbtPPwFVREpIyqXIDXr55Ct2a1AejTNoNbTzsagA+mrg7u88WMtcHlaDfl5nH1W1kATF2x9TCXVkSk9KpcgAOc07UxAB0a1eCaAW3CFr8K5ZzjDy/+zI49vuaV5ATfP8eHU1cH11PJ27dfa6uISKVUJQP8d10asfzRoTSuVQ2AHi3rxtwv88FxLA1pNhk/bwMtRo7hlg9m8Nd3pgFww3vTyXxwHM65Eh174YYcRn08k5w9+YBvDPoLE5aU5XRERGKykgZTecjMzHRZWVmH7XgBzjk6/G0su/NLvy7KhSc0pVpSPGNmrqNbs9rszt/Phh17eOOK7tRNTyIxPo6pK7byh5d+Zn+Bo371ZKbcOZAWI8cAsOyRIZgVPUpGRKQoZjY11k3jq2QNPJKZ8cW1vcO2HexQwvd+XcXrPy1nY04eX81Zz/cLs5m/Poeej4zn4lcmU1DgOO+FSewv8H0hbswJb3ZZv2NP2U6iGIs35pK1XLeYEznSHBEBDtCmfnW+uuEkAM7t1ji4jkqrjLQyf/aU5Vt4e/KKqO3rtxeG9s68fWzKzeOXpZvJ21fyXwJ78vcz8qOZxbbDD3zqe85/0TeqJmdPPn0f/45pK9UhK1LVeX4iz8Fof1QNlj48hLg4Y3+BIykhjuSEOP789rTgPknxcewtxeqFd382J2rbsFd+CT7emJPHwKd+AODe33Xgj71bsjk3jzppScU2rYyZuY73fl3Fyi27ePiczrSoV/wXzoxV21m5ZRdPjl3AO8N7HvR5iIh3HDE18IC4uMJZm2d3bcxpHY8KDjUEeHdED+4aeky5HCt0XPlFr0wOPr73i7m89csKjn9wHKc98wPfL8xm6gpfE0jOnnzWbNsd9VmTlmym/5MTWJKdy/B/ZbEnRnu+cw6HrwlHze0iVd8RF+CR4uKMv/RvHXyenpxIcmI8AEM7N+Tx8489JMe9+1Pf7UMXbsjl8temcN4LP5Odk0fne7+m96PfhpQv/H13fTKbb+ZuYMqy6DbvtyevZF1Is03+/gKthS5ShZU5wM0s3sx+M7PR5VGgimBm/Hj7AG4Y2JZ2DdJpWdfXTNGlaU3+kNmU4Se1jHpPV/8t3QLKY8XDEx4aF3ycm+cbmx5XRFV6f4Fj+658utz3dXDbXZ/O5rYPZwJgGN0e+Ib+T0446HJE3sXonckr+W7BxoP+HBE5tMqjDfx6YB4Qey1Xj2hSO5UbBvpGpvRpW4//XN2L45v7ZnTeObQDe/cVMHrmOkYNOYZbPpjBW1f14P8mLuPpcQvJqJ7MlDtO4Yb3p/PZ9LXlUp5O94wF4Op+rcK2Bzons3Pz6HL/11HvC/hx8SYAcvbsY/vufBLjjc25e2lSu1rMNvd/TljMzFXbOaFlHR4YPZf3RvRk7todZK3Ywpez1gO+JXvBN9GpV+u6wXH2IlIxyjQO3MyaAG8CDwE3OefOKG7/ihoHfqis2rKLkx7/jo//cmJw+v7m3DyOf3DcAd4ZblCHBnwzd0PM12pWS2T77vyo7ed0bcwnv60p0ee3P6o6GdWTmbjIF+oPnt2JS3o2D9snMF49oFeruvy8dHPYtuWPDiU3bx+d7hlL64w0xt/cv0THv+L1Kfy8dDMXntCMYd2bcfRR1Uv0voD/zlpHanICfdvW49WJy6idlkSv1nX5+/hFfDlrHTPvPe2gPk/Eaw7VOPBngNuAIhtazWyEmWWZWVZ2dnYZD1e5NK2TyvJHhwbDG6BuejLf3Ng3+PyWUwvHmxd1C7jzj29S5DFihTfA13PWl7ic89fnBMMbfE0t//l1FQs35LA2RocpEBXe4PtyCow3D21rDzVn7Xbu+Wx2cEYrwHcLstmTX8Abk5Zz2jM/HLC8kxZvosXIMcHO3D+/PY3LX5vCvHU5PPTlPG75YAZDn5vIe7+uCi6DUF727ivg9g9nFvnvIlKZlDrAzewMYKNzbmpx+znnXnbOZTrnMjMyMkp7OE9p26A642/ux/wHBnPWcY2D2yfePoCsuwYGn397cz/evLJ7iW8NB9CkdjX+eGILdu4t/axSgNs+msmpT//AiY9+y449sb8kIr320zL++PqvAOzau59+T3zH/PU7+Gz6Gmav2c7YOesZ+tyPvPmzb0z8h1NX8+Ws6NvZtRg5hn//Ej1uHnzj5V/43rf0wKzV24ITo4CwmbTbdhWWed323Qx9bmLYuPuS2r47n1s/mBFc+uCHhdm8n7WKez6PHhYqUtmUpQbeGzjTzJYD7wEnm9m/y6VUVUDrjHRSEuNpXMsXuN/c2JfE+DjqpSdzSc9mdG9Zh1YZ6fRrl0HHxuHdBzcOLHqWaONa1RjWvVnU9lYHGB9enGPvLbotPVR2xOzSFZt3MfiZiVz/3nTO+PuPLFifE/Wev4SMsQ9116ezOfGR8Tz21XxajhrD6z8tI39/AR3vGRv8tRAfFxdWE84p4oum1yPfMmftDh4fOz9q1M0Vr0/hxvenh23bmLOH3o9+y+KNObz0/RI+mLqatyevBAjOAUiIcXOQnXn7aDFyDGNmrmPsnPVc8NLP5JdylM+m3LwSr68jUpRSd2I650YBowDMrD9wi3PuknIqV5URF2fce2bHsG0Pnt057HmNlETeHd6TlvXSWLoplx4t6/LGpGVs3ZXPskeGcN8Xc3lj0nJSEuN47LxjY07meWd4T9JTEhj8zA+s3loYeie1rRfWfFIW/8laXezrB3u7urXb9wQX+rrvi7nc98XcsNeH/yu8v+Qdf8gW5eNpa2idkc41A9oEt323wNdsV796Mnn7Crj3zI6Mnb2eNdt289pPy0lP9v0vYPju2hT4wkmMj67brNyyC4Bnxy9k4YZcADbn7uWomrGbxnzH38hDY+bx5XUnkeRf7XLZpp0MeHIC953ZkctPbFHsOUm4vfsK6HzvWB45tzPndiu66fFIcUTNxKzMerX2rZgYCIMvru3Dwg05mBm3nnY0DWqkMKJvq+Bt4367exDVkuKZumIr4+ZtCL7vnxd348x//BT83BNa1OEfF3XDOYeZsXHHHgY9feB26Mro6yI6ekN9N38jH09bzWPnHUtmizrB7S/5b6f3uy6NgrNmDV8zD/gmdj359YLg/r+t2srctTtISogjN28fw17+hRNbR69quXVX8QE+6qNZrN+xh+zcvOConXX+XxVjZq0rNsBHz1zLqI9mkXX3QJIT4g947oeac45flm6hZ6s6FbYw27Zde8nbV8DDX85XgFNOE3mccxMONAJFDk6T2qmc3L4BAGnJCfy5f+uwe37WTksiJTGe3m3qcc/vCmv4xzapxf1ndeSEFr6O1Z6t6lKzWiK1UpOoWS2Rtg2qs/ThIcH9Q4cpZjavzTUDWnOZ/05G7w7vSesSrBVz++D2JT6vGimHts6QtWIrS7J3cv6LP/PE2PlRr5/3wqTg48nLtrBl517Atwzwx9MKR/Ws2rKbIc9NZOBT33P28z+xO38/4+f7xsKv21bY1r5tVz7fzt9An8e+ZUl2btixvp2/IbiI2VNfL2T11l20vuNLpq/eBkBuER2w4+dtYNKSTTwwei45efv4eNoanHM8OHpukaOVArJz8vh2/gb6P/EdX80uWUd3do6vOWfsnPVMWlz0r7V3pqxk2Cu/cOP704tszgq1Yccevp0fu7zZOXl86h9FNX7eBibH6DSPZX+w2ckd1JpCFWn6qm1szDk0i9kd8TMxq6LLerXgneE9+eKvfejesk7U63FxFmxnH3hMA5Li4+jStBYf/E8vbj2tPbcNbs/TF3ShZ6s6XNTDF+bjb+5Hd3+N9qZB7Zg08uTg5/05ZCYrwOPnHcu4m/rSom7h/Ulb1Uvjs2t6c/vpJQ/7snr+u+LXYV+8sTBwD9Q8FConrzB4//Xzcq58I4vVW3dzyv9+z6otu7jhvd9oMXIMV75R2AT00bTV/OPbxewvcDz+la+mX9Tyxle9mcVFr0wmkFWjPp7FZ9PX8uqPyxj+ryy278rnFn/H69ade1m5eVfwvfd+Pocr38hi+eZd3OvviF28MZcWI8fEXLFySXYuJzw0jpajvuTqt6Zy0auTo/YJWORvNvp0+lpGfjQr5mdNWlL4BfCHl37myjeyKCiIbuv/05u/csP709mycy9XvZnFBS//ErVPLHn5vj6HTbl7Ofqur4Lbt+7cy7gDfLmN+ngWA0oxsa009u0vCC53cfbzP3F2yK/i8qQmlCoqMT6Ozk1qFvn6tSe34dxujWlaJ5VZ951KvFnwZ3F6cgLndPX9PL2ydwsu69WcxPg4bhzUjmGv/EL3lnWihkTeNKhdsA38vOObEB9nNKiRwvLNu5h42wCa+m823aVpLf6Q2ZS2d/437P2RbfX1qyfToVENJiwo+dDTlMQ49uQf3qUD/htRyx3w5AT2xQgs8C1JHKogpBOzoMDxv98soHZqUnDbzpAvik+nF/46uG/0HD6etoYl2bn8ttJXm1/+6FCmrdzKvPU7gvut37GHD7JWBYeiDnvlF/52RgeObVKLHXvyOaltRtiviYDXf1pG2/rV6d2mLnv3FwSbb/YVFP7bjpm1jsfy9pGaGB9cX+iU//0++HqvVnVZ4f9i+WDqKi44IbzjfZW/nya007nFyDFMufMU6ldPYeyc9VRPSeDE1vXC3reniFr31f+eGlxeYsIt/WP2E707pfg+lNLaviufmqnhI8mufmsq4+dvDA4RXluKEVIloQA/QsXFWTBUi2tfNTMS433/g/ZqXZf5DwwmJbFw/0ATzHWntA0GeKCp5x8XdePb+RuCxwkIdBBe3qs59Wuk8Oak5bRrUJ2JizYx4OgMWmekc8eQY3BA6zu+LPY8eraqw+w1O8jN21dseJd2lcmDVVR4x+Kcrynhs+lreHDMvKjXQ4eKhn6RBZp6AuEN8OrEpTE/49YPZ5KW5Lte+ftd2KqZj59/LL/FWHY40Jl8x5D2PPzlfH4aeTKNa1VjZ154eAZmCy966PSoTt/QeQS3fzSLZZt2ccPAtkxZtoW+7TKCw0Mjh7BOW7GVwZ0acvVbvtHJXZvV4pO/9OY/v67ipyWbuDRiAlq/J77jrC6NWBrSfDVm1rqwjuxI01ZupUuTWmFNksUZ8OQE2jVI56VLC+fRrN22m0v/bzJ3De3AFW/8ypO/78L5xzdh0pJNYQvXfTi15L/sSuOIuCOPHB4LN+QwY9U2fp/Z9KDe55zjibEL+OeEJVx/SltuDLnZRmCG6L+v6sEbk5bTu03dYMCkJcUz5/7B7C9w5O8vYOqKrVwcowmga7Na/H1YV/o89h3/0681L/rHmS9/dGjUDNRQreqlhd1yrzgdGtZg7rodB97Rgx4+pzN3fBLdZBIw+to+rN22mxFvFTslhAY1ktmwI4/vb+3PGX//kZw9+6iTlhTshwDfrOGNOXlh20Kv018HtOEf3y0+YJkv7dmcP53Ukn5PTOCBszpyaa8WYde6TloSU+8ayOqtu6mdlhQcjQS+L5Vj7/2a/kdncEXvllz+2pRgOQKeGDuf579bQpv66SzemMtJbevx5hXd6fHI+KjhtqHnUVpFzcRUDVzKTbsG1WnX4OCmyYOvlv/7zKa89+sqzu3WOOy1P/VpyaKNufRpW48+bX0/p7s2q83Zz//En07y1f7j44z4OF+H7lnHNeKz6Wt54KyOwdpmjZREmtROZdrdg6iTlnHyEDEAAAwjSURBVESzOqmkJftqpTcMbMsz4xbFLFd2MTfRuHPIMTz0ZWGN98FzOnHuPycVuT/AbYOPDrZ/d2lSkxmrtxe7f2Xx/AEC84y//1iiz9mww/fv+dvKbcH2/dCgBt+s4Uid7x0bfFyS8AZ465cVvOWfLHb3Z3OoG7HY3Jade7nstSlMXLSJlvXSeOTczvRs5Rtl9PhXvs7vCQuyw3753PHJLH5dtoXOTWoG5wnU8Td5TVy0iVbF/FpMTTo0o4gU4FIptKyXxrS7B0Vtv+uMDlHbjmtai1n3nhpWawoI/ChOTSp8LdCWXCfN9z/bRT0K22NvGNiuyAB/d3jPsHBq1yCdhRty6dsug+F9WzF77XbmrN3Btl35tK2fHtwvMd7I3x/9y/aKE1vSt20Gq7fuCoZLUZrWqcaqLZVjOn+s9enL4oaIiVUHklMOyyUEhpGGCvS5LNu0kwv9nagTbxvAFzOiZw9D4TyERSGd3yW9z+6hCnCNQhFPqp6SGHMscveWvlpU6/rpPH9RNyC8szCWwFDJCbf0570RvrsYdW9Rh06Na/LxX04M7vfiJccz42+n8q8ruwPw7IVdGXdTP7LuGkj1lER+GXUKk0aezKKHhoR9/mPndWbxQ6dTLSmeTo1rMrhTQ24f3J7OjYvuZB7Rt3XUtsfO6xy8LWDAO8N7lPq2gMc1LVwSOTDstKqasWrbgXfCN3O4qPWHYpm1pmS/ojbl7i3R0MuDpQCXKmVY96ZMvG0AxzWtxemdjuLqfq14+oLjin3Pf6/vy/wHBtOiXho9W9Vl6cNDgkHerVltHjvPN3O2Yc1qUaMNQh1VM4VG/sk6D5/TmVtPO5oTW9dlSOeGJER08h3bpBaf/7U3Z3ZpBPjG0k+58xT6tcvgt7sH0alR9OrMfdpm0P6owu2DOx5Ft2a1i1zW95XLCptMA01ToXefun5g22DN8NkLu/LrnYXr9Pw86mQGHtMg+Hz5o0P54dYBVEus+AlFkRoVM5HqYB0okMfd1K/Unx15o/PyoACXKsWscHRNXJwx6vRjaF63+BpqUkJc2MiauDgLDo0DuOCEZix/dCjVDuJn8EU9mnHNgDa8M7wn1YtYrMzMePbC43j1skxG9G1F/eopvHlld2qnJUWV+be7BwWD+u0/9eDak9vw4qXHk5IYz7MXduXFS7oF9z2mYQ2WPzqUQR18Ady3XQZn+xdVG9q5IT1b+cbzJ8XHBaf3J8bHkVE9mfZHVeeWU9vRsGY1Xr08k+9v7c/Po3xj/pvVTWXi7QNihthlvZrz92Fdg8+f/H2X4OPR1/YJPh5zXeHjq/u24qVLj4/5b/P5X3sHH3/8lxM5uX39mPv9+6oeYe3bxzevzXMh5Yjl02t6F/t6cdrUT+ektvUOvKNf7zaFs3ebR4zGKg9qAxepQGbGwA4NorbXSUvixUuO5/jmtcmoHt4B17tNPXq3qRe27+BODcm6ayC9HhnPbYMLa9k/jTyZuv5Zu4FREIHh3HFmjDq9Pbd/NIsa1XxR8NUNhUshA1FfJPXSk6mblhS2rU39dO47syNmRr+jM4g3Iy05gcGdjiLeLPjFVz0lgY6NanLzoHYc27QW/dplBG9QAvDldSfRIeSXR1J8HBf3bEa3ZrV57Y8nBEeRnNetCY1rV+MPmU1oUjuVv3/r+/x/XtyNk9vXJzE+jg+yVjFx0Sau7tuKn5ZsYvaaHSQnxDHh1v40rFkt2Mk95ro+7C9wweUnJt42gKSEOLbtyg8uffw//VqzJDuX609pC8A9v+vIwKcKx7yDb/LabR/NjLqOdww5hpmrt/Prsi1Rv8LKgwJcpJIa3Omog9q/XnpyVPt7rOaVwISchHjjghOaRU2yORAz4/zjm9CvXQbpKQn0bl0v2B8RujRyaCfzhFv6U92/jMK1/iAM3f/MLo3Cwhtg4UOnxzz+k78/Nqz/I7AWTWpSfPCX1FtX9WDvvoLgL4y8ffvD5jtc2qsFF/doHvyl9dk1vVmwPif4661BjRRuHNiOp8ctpE39dEaGzCBuUz+dVy/L5E8hi6394YSmUQE+qEMDOjaqScdGNWOuIFoeFOAiR5ibTz2aa96ZRvuDvDNSqNAmkpKINTMSCsOwZ4yFwooS2Xl9/5mdaFkvjZPaht9vIBDeEHuyWmgzWZemtejSNPw+t3/u35q66Umc07Vx5FvDfjV1jPjiubhHM96evDL4hXUoKcBFjjC929Rj+t9OrehiBMVqQjoYNVMTg/ezLU9JCXFRtx6MNPCYBrx6eWFncc1qidx3ZkdqpSYy/KRWxbyzfCjARURKYf4Dg8Nu/DH9b4NIiI8jIT6OW087PIu2KcBFxBOeG9aVmtVKfvvBQy0lYkhlrdSkIvY8dBTgIuIJgTHzUkjjwEVEPEoBLiLiUaUOcDNLMbMpZjbDzOaY2X3lWTARESleWdrA84CTnXO5ZpYI/Ghm/3XOlezeSCIiUialDnDnuxNEYF3FRP+fw3d3CBGRI1yZ2sDNLN7MpgMbgW+cc1G3QzGzEWaWZWZZ2dklv7+hiIgUr0wB7pzb75w7DmgCdDezTjH2edk5l+mcy8zIyIj+EBERKZVyGYXinNsGfAcMLo/PExGRAyv1TY3NLAPId85tM7NqwNfAY8650cW8Jxso/l5SRasHbCrle71G51r1HCnnCTrXQ6G5cy6qCaMso1AaAm+aWTy+mvx/igtvgFgFKCkzy4p1V+aqSOda9Rwp5wk618OpLKNQZgLF3/pCREQOGc3EFBHxKC8F+MsVXYDDSOda9Rwp5wk618Om1J2YIiJSsbxUAxcRkRAKcBERj/JEgJvZYDNbYGaLzWxkRZenLMysqZl9Z2Zz/as4Xu/fXsfMvjGzRf6/a/u3m5k95z/3mWbWrWLP4OD5l1z4zcxG+5+3NLPJ/nN638yS/NuT/c8X+19vUZHlPlhmVsvMPjSz+WY2z8x6VdXramY3+v/7nW1m7/pXJ60S19XMXjOzjWY2O2TbQV9HM7vcv/8iM7v8UJS10ge4f5z588DpQAdgmJl1qNhSlck+4GbnXAegJ3CN/3xGAuOdc22B8f7n4Dvvtv4/I4AXDn+Ry+x6YF7I88eAp51zbYCtwFX+7VcBW/3bn/bv5yXPAl8559oDXfCdc5W7rmbWGLgOyHTOdQLigQupOtf1DaJnlR/UdTSzOsA9QA+gO3BPIPTLlXOuUv8BegFjQ56PAkZVdLnK8fw+AwYBC4CG/m0NgQX+xy8Bw0L2D+7nhT/41skZD5wMjAYM38y1hMjrC4wFevkfJ/j3s4o+hxKeZ01gWWR5q+J1BRoDq4A6/us0GjitKl1XoAUwu7TXERgGvBSyPWy/8vpT6WvgFP7HErDav83z/D8luwKTgQbOuXX+l9YDDfyPvX7+zwC3AQX+53WBbc65ff7noecTPFf/69v9+3tBSyAbeN3fXPSqmaVRBa+rc24N8CSwEliH7zpNpWpe14CDvY6H5fp6IcCrJDNLBz4CbnDO7Qh9zfm+sj0/vtPMzgA2OuemVnRZDoMEoBvwgnOuK7CTwp/ZQJW6rrWBs/B9aTUC0jiCFrKrTNfRCwG+Bmga8ryJf5tn+e9g9BHwtnPuY//mDWbW0P96Q3xrrIO3z783cKaZLQfew9eM8ixQy8wCyziEnk/wXP2v1wQ2H84Cl8FqYLUrXBP/Q3yBXhWv60BgmXMu2zmXD3yM71pXxesacLDX8bBcXy8E+K9AW38PdxK+zpLPK7hMpWZmBvwfMM8591TIS58DgZ7qy/G1jQe2X+bv7e4JbA/5KVepOedGOeeaOOda4Ltu3zrnLsa39PD5/t0izzXwb3C+f/9KUdM5EOfcemCVmR3t33QKMJcqeF3xNZ30NLNU/3/PgXOtctc1xMFex7HAqWZW2/+L5VT/tvJV0Z0FJexQGAIsBJYAd1Z0ecp4Ln3w/fyaCUz3/xmCr01wPLAIGAfU8e9v+EbhLAFm4ev5r/DzKMV59wdG+x+3AqYAi4EPgGT/9hT/88X+11tVdLkP8hyPA7L81/ZToHZVva7AfcB8YDbwFpBcVa4r8C6+tv18fL+srirNdQSu9J/zYuCKQ1FWTaUXEfEoLzShiIhIDApwERGPUoCLiHiUAlxExKMU4CIiHqUAFxHxKAW4iIhH/T9t+HnO380zsQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecoderOnlyTransformer(\n",
              "  (embedding): Embedding(34543, 512)\n",
              "  (positional_embedding): SinusoidalPositionalEncoding()\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (decoder_blocks): ModuleList(\n",
              "    (0): DecoderBlock(\n",
              "      (attention): MultiheadMaskedAttention(\n",
              "        (W_QKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLPBlock(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (gelu): GELU(approximate=none)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): DecoderBlock(\n",
              "      (attention): MultiheadMaskedAttention(\n",
              "        (W_QKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLPBlock(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (gelu): GELU(approximate=none)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (2): DecoderBlock(\n",
              "      (attention): MultiheadMaskedAttention(\n",
              "        (W_QKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLPBlock(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (gelu): GELU(approximate=none)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (3): DecoderBlock(\n",
              "      (attention): MultiheadMaskedAttention(\n",
              "        (W_QKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLPBlock(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (gelu): GELU(approximate=none)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (4): DecoderBlock(\n",
              "      (attention): MultiheadMaskedAttention(\n",
              "        (W_QKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLPBlock(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (gelu): GELU(approximate=none)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (5): DecoderBlock(\n",
              "      (attention): MultiheadMaskedAttention(\n",
              "        (W_QKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLPBlock(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (gelu): GELU(approximate=none)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (6): DecoderBlock(\n",
              "      (attention): MultiheadMaskedAttention(\n",
              "        (W_QKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLPBlock(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (gelu): GELU(approximate=none)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (7): DecoderBlock(\n",
              "      (attention): MultiheadMaskedAttention(\n",
              "        (W_QKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLPBlock(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (gelu): GELU(approximate=none)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (unembed): Linear(in_features=512, out_features=34543, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "optimizer = t.optim.Adam(transformer.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "train(transformer, optimizer, loss_fn, train_dataloader, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling"
      ],
      "metadata": {
        "id": "3YhQnG76tkBh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ZTVzTE3f2hcC"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch as t\n",
        "import torch.nn.functional as F\n",
        "from torchtyping import TensorType\n",
        "\n",
        "def greedy_search(logits: t.Tensor) -> int:\n",
        "    '''\n",
        "    logits: shape (vocab_size, )\n",
        "\n",
        "    Return: the most likely token (as an integer)\n",
        "    '''\n",
        "    item = logits.argmax().item()\n",
        "    assert isinstance(item, int)\n",
        "    return item\n",
        "\n",
        "def sample_basic(logits: t.Tensor) -> int:\n",
        "    '''\n",
        "    logits: shape (vocab_size, ) - unnormalized log-probabilities\n",
        "\n",
        "    Return: a sampled token\n",
        "    '''\n",
        "    item = t.distributions.categorical.Categorical(logits=logits).sample().item()\n",
        "    assert isinstance(item, int)\n",
        "    return item\n",
        "\n",
        "def apply_temperature(logits: t.Tensor, temperature: float) -> t.Tensor:\n",
        "    '''\n",
        "    logits: shape (vocab_size, )\n",
        "\n",
        "    Return: shape (vocab_size, )\n",
        "    '''\n",
        "    assert temperature > 0\n",
        "    return logits / temperature\n",
        "\n",
        "def apply_freq_penalty(input_ids: t.Tensor, logits: t.Tensor, freq_penalty: float) -> t.Tensor:\n",
        "    '''\n",
        "    input_ids: shape (seq, )\n",
        "    logits: shape (vocab_size, )\n",
        "\n",
        "    Return: shape (vocab_size, )\n",
        "    '''\n",
        "    id_counts = t.bincount(input_ids.reshape((-1,)), minlength=logits.shape[0])\n",
        "    return logits - freq_penalty * id_counts\n",
        "    \n",
        "def sample_top_k(logits: t.Tensor, top_k: int) -> int:\n",
        "    '''\n",
        "    logits: shape (vocab_size, ) - unnormalized log-probabilities\n",
        "    top_k: only consider this many of the most likely tokens for sampling\n",
        "\n",
        "    Return: a sampled token\n",
        "    '''\n",
        "    assert top_k > 0\n",
        "    _top_k_logits, top_k_indices = logits.topk(top_k)\n",
        "\n",
        "    top_k_logits = t.ones_like(logits) * float(\"-inf\")\n",
        "    top_k_logits[top_k_indices] = _top_k_logits\n",
        "\n",
        "    return sample_basic(top_k_logits)\n",
        "\n",
        "\n",
        "def sample_top_p(logits: t.Tensor, top_p: float, min_tokens_to_keep: int = 1) -> int:\n",
        "    '''\n",
        "    logits: shape (vocab_size, ) - unnormalized log-probabilities\n",
        "\n",
        "    Return: a sampled token\n",
        "    '''\n",
        "    assert top_p > 0\n",
        "    assert min_tokens_to_keep > 0\n",
        "\n",
        "    sorted_logits, sorted_indices = logits.sort(descending=True)\n",
        "    cumulative_probs = F.softmax(sorted_logits, dim=0).cumsum(dim=0)\n",
        "\n",
        "    reject_index = min(t.searchsorted(cumulative_probs, top_p) + 1, len(sorted_indices))\n",
        "    top_p_indices = sorted_indices[:reject_index]\n",
        "\n",
        "    top_p_logits = t.ones_like(logits) * float(\"-inf\")\n",
        "    top_p_logits[top_p_indices] = logits[top_p_indices]\n",
        "\n",
        "    return sample_basic(top_p_logits)\n",
        "    \n",
        "\n",
        "def apply_sampling_methods(\n",
        "    input_ids: t.Tensor, logits: t.Tensor, temperature=1.0, freq_penalty=0.0, top_k=0, top_p=0.0\n",
        ") -> int:\n",
        "    '''\n",
        "    Return the next token, sampled from the model's probability distribution with modifiers.\n",
        "x\n",
        "    input_ids: shape (seq,)\n",
        "    '''\n",
        "    assert input_ids.ndim == 1, \"input_ids should be a 1D sequence of token ids\"\n",
        "    assert temperature >= 0, \"Temperature should be non-negative\"\n",
        "    assert 0 <= top_p <= 1.0, \"Top-p must be a probability\"\n",
        "    assert 0 <= top_k, \"Top-k must be non-negative\"\n",
        "    assert not (top_p != 0 and top_k != 0), \"At most one of top-p and top-k supported\"\n",
        "\n",
        "    if temperature == 0:\n",
        "        return greedy_search(logits)\n",
        "    if temperature != 1.0:\n",
        "        logits = apply_temperature(logits, temperature)\n",
        "    if freq_penalty != 0.0:\n",
        "        logits = apply_freq_penalty(input_ids, logits, freq_penalty)\n",
        "    if top_k > 0:\n",
        "        return sample_top_k(logits, top_k)\n",
        "    if top_p > 0:\n",
        "        return sample_top_p(logits, top_p)\n",
        "    return sample_basic(logits)\n",
        "\n",
        "\n",
        "def sample_tokens(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    initial_text: str,\n",
        "    max_tokens_generated=30,\n",
        "    **kwargs\n",
        ") -> str:\n",
        "    '''\n",
        "    Sample tokens until the model outputs `tokenizer.eos_token_id` or the specified token limit is reached.\n",
        "\n",
        "    Return: the prompt and continuation concatenated\n",
        "    '''\n",
        "    model.eval()\n",
        "    input_ids = tokenizer.encode(initial_text)\n",
        "    generated = []\n",
        "\n",
        "    max_tokens_generated = min(max_tokens_generated, model.config.max_seq_len - len(input_ids))\n",
        "\n",
        "    for _ in range(max_tokens_generated):\n",
        "        new_input_ids = t.tensor(input_ids + generated, dtype=t.int64, device=device)\n",
        "        new_input_ids_1hot = t.nn.functional.one_hot(new_input_ids, tokenizer.vocab_size)\n",
        "\n",
        "        logits = model(new_input_ids.unsqueeze(0))[0, -1]\n",
        "\n",
        "        new_token = apply_sampling_methods(new_input_ids, logits, **kwargs)\n",
        "        generated.append(new_token)\n",
        "        \n",
        "        if new_token == getattr(tokenizer, \"eos_token_id\", None):\n",
        "            break\n",
        "\n",
        "    return tokenizer.decode(input_ids + generated)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate new samples"
      ],
      "metadata": {
        "id": "ExLiiey4tnFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tokens(\n",
        "    transformer, \n",
        "    tokenizer, \n",
        "    \"To be or not to be, that is the question.\", \n",
        "    temperature=0.5, \n",
        ")"
      ],
      "metadata": {
        "id": "rD_AT75i7sv8",
        "outputId": "95b17754-f3de-4f98-fa1c-ef00678e2380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To be or not to be, that is the question._] I have been been in a king\\nThat the man of a good '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NI4hEWIKDFPP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.8 ('notes-Szvzhu7a')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "8e19e98c1663512e4ab445fbd0ba1d11a615d7c9869472ffe0065bf2036c088a"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "af454aa3efac4bcc9c3f110f7c88e041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4daafa4eb41c471698f3a01e9f515177",
              "IPY_MODEL_64318378a3f546c29327940a34f04cd2",
              "IPY_MODEL_355662bf44a0421a8a054b8bd3837d9f"
            ],
            "layout": "IPY_MODEL_af0dfa63f670428ebf53a53311a03fbd"
          }
        },
        "4daafa4eb41c471698f3a01e9f515177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61ab178441d443e8a8afd5fe46e7ebaf",
            "placeholder": "",
            "style": "IPY_MODEL_9106ef431b0d41e69641533d31467350",
            "value": "epoch = 1, loss = 3.5142: 100%"
          }
        },
        "64318378a3f546c29327940a34f04cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6f0c6d3b67c4539969e240e1bbfdbb8",
            "max": 1036,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c562aee6241a4ca18d27fc7db143f64c",
            "value": 1036
          }
        },
        "355662bf44a0421a8a054b8bd3837d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_558e0eb22457491685b52ad9163b975a",
            "placeholder": "",
            "style": "IPY_MODEL_a60238bfd84845159e951a9f9b63a704",
            "value": " 1036/1036 [02:46&lt;00:00,  6.06it/s]"
          }
        },
        "af0dfa63f670428ebf53a53311a03fbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61ab178441d443e8a8afd5fe46e7ebaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9106ef431b0d41e69641533d31467350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6f0c6d3b67c4539969e240e1bbfdbb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c562aee6241a4ca18d27fc7db143f64c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "558e0eb22457491685b52ad9163b975a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a60238bfd84845159e951a9f9b63a704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}